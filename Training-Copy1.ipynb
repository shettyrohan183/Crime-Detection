{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d714c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import time\n",
    "from time import time\n",
    "import firebase_admin\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow\n",
    "from firebase_admin import credentials , firestore ,db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "da63caf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 4GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e939a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from time import time\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9658b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# from keras.utils import np_utils\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Data Generator inherited from keras.utils.Sequence\n",
    "    Args: \n",
    "        directory: the path of data set, and each sub-folder will be assigned to one class\n",
    "        batch_size: the number of data points in each batch\n",
    "        shuffle: whether to shuffle the data per epoch\n",
    "    Note:\n",
    "        If you want to load file with other data format, please fix the method of \"load_data\" as you want\n",
    "    \"\"\"\n",
    "    def __init__(self, directory, batch_size=1, shuffle=True, data_augmentation=True):\n",
    "        # Initialize the params\n",
    "        self.batch_size = batch_size\n",
    "        self.directory = directory\n",
    "        self.shuffle = shuffle\n",
    "        self.data_aug = data_augmentation\n",
    "        # Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\n",
    "        self.X_path, self.Y_dict = self.search_data() \n",
    "        # Print basic statistics information\n",
    "        self.print_stats()\n",
    "        return None\n",
    "    def search_data(self):\n",
    "        X_path = []\n",
    "        Y_dict = {}\n",
    "        # list all kinds of sub-folders\n",
    "        self.dirs = sorted(os.listdir(self.directory))\n",
    "        one_hots = utils.to_categorical(range(len(self.dirs)))\n",
    "        for i,folder in enumerate(self.dirs):\n",
    "            folder_path = os.path.join(self.directory,folder)\n",
    "            for file in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path,file)\n",
    "                # append the each file path, and keep its label  \n",
    "                X_path.append(file_path)\n",
    "                Y_dict[file_path] = one_hots[i]\n",
    "        return X_path, Y_dict\n",
    "    \n",
    "    def print_stats(self):\n",
    "        # calculate basic information\n",
    "        self.n_files = len(self.X_path)\n",
    "        self.n_classes = len(self.dirs)\n",
    "        self.indexes = np.arange(len(self.X_path))\n",
    "        np.random.shuffle(self.indexes)\n",
    "        # Output states\n",
    "        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n",
    "        for i,label in enumerate(self.dirs):\n",
    "            print('%10s : '%(label),i)\n",
    "        return None\n",
    "    def __len__(self):\n",
    "        # calculate the iterations of each epoch\n",
    "        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n",
    "        return int(steps_per_epoch)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get the data of each batch\n",
    "        \"\"\"\n",
    "        # get the indexs of each batch\n",
    "        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # using batch_indexs to get path of current batch\n",
    "        batch_path = [self.X_path[k] for k in batch_indexs]\n",
    "        # get batch data\n",
    "        batch_x, batch_y = self.data_generation(batch_path)\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # shuffle the data at each end of epoch\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def data_generation(self, batch_path):\n",
    "        # load data into memory, you can change the np.load to any method you want\n",
    "        batch_x = [self.load_data(x) for x in batch_path]\n",
    "        batch_y = [self.Y_dict[x] for x in batch_path]\n",
    "        # transfer the data format and take one-hot coding for labels\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_y = np.array(batch_y)\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def normalize(self, data):\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "        return (data-mean) / std\n",
    "    \n",
    "    def random_flip(self, video, prob):\n",
    "        s = np.random.rand()\n",
    "        if s < prob:\n",
    "            video = np.flip(m=video, axis=2)\n",
    "        return video    \n",
    "    \n",
    "    def uniform_sampling(self, video, target_frames=64):\n",
    "        # get total frames of input video and calculate sampling interval \n",
    "        len_frames = int(len(video))\n",
    "        interval = int(np.ceil(len_frames/target_frames))\n",
    "        # init empty list for sampled video and \n",
    "        sampled_video = []\n",
    "        for i in range(0,len_frames,interval):\n",
    "            sampled_video.append(video[i])     \n",
    "        # calculate numer of padded frames and fix it \n",
    "        num_pad = target_frames - len(sampled_video)\n",
    "        padding = []\n",
    "        if num_pad>0:\n",
    "            for i in range(-num_pad,0):\n",
    "                try: \n",
    "                    padding.append(video[i])\n",
    "                except:\n",
    "                    padding.append(video[0])\n",
    "            sampled_video += padding     \n",
    "        # get sampled video\n",
    "        return np.array(sampled_video, dtype=np.float32)\n",
    "    \n",
    "    def random_clip(self, video, target_frames=64):\n",
    "        start_point = np.random.randint(len(video)-target_frames)\n",
    "        return video[start_point:start_point+target_frames]\n",
    "    \n",
    "    def dynamic_crop(self, video):\n",
    "        # extract layer of optical flow from video\n",
    "        opt_flows = video[...,3]\n",
    "        # sum of optical flow magnitude of individual frame\n",
    "        magnitude = np.sum(opt_flows, axis=0)\n",
    "        # filter slight noise by threshold \n",
    "        thresh = np.mean(magnitude)\n",
    "        magnitude[magnitude<thresh] = 0\n",
    "        # calculate center of gravity of magnitude map and adding 0.001 to avoid empty value\n",
    "        x_pdf = np.sum(magnitude, axis=1) + 0.001\n",
    "        y_pdf = np.sum(magnitude, axis=0) + 0.001\n",
    "        # normalize PDF of x and y so that the sum of probs = 1\n",
    "        x_pdf /= np.sum(x_pdf)\n",
    "        y_pdf /= np.sum(y_pdf)\n",
    "        # randomly choose some candidates for x and y \n",
    "        x_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=x_pdf)\n",
    "        y_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=y_pdf)\n",
    "        # get the mean of x and y coordinates for better robustness\n",
    "        x = int(np.mean(x_points))\n",
    "        y = int(np.mean(y_points))\n",
    "        # avoid to beyond boundaries of array\n",
    "        x = max(56,min(x,167))\n",
    "        y = max(56,min(y,167))\n",
    "        # get cropped video \n",
    "        return video[:,x-56:x+56,y-56:y+56,:] \n",
    "    \n",
    "    def color_jitter(self,video):\n",
    "        # range of s-component: 0-1\n",
    "        # range of v component: 0-255\n",
    "        s_jitter = np.random.uniform(-0.2,0.2)\n",
    "        v_jitter = np.random.uniform(-30,30)\n",
    "        for i in range(len(video)):\n",
    "            hsv = cv2.cvtColor(video[i], cv2.COLOR_RGB2HSV)\n",
    "            s = hsv[...,1] + s_jitter\n",
    "            v = hsv[...,2] + v_jitter\n",
    "            s[s<0] = 0\n",
    "            s[s>1] = 1\n",
    "            v[v<0] = 0\n",
    "            v[v>255] = 255\n",
    "            hsv[...,1] = s\n",
    "            hsv[...,2] = v\n",
    "            video[i] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "        return video\n",
    "        \n",
    "    def load_data(self, path):\n",
    "        # load the processed .npy files which have 5 channels (1-3 for RGB, 4-5 for optical flows)\n",
    "        data = np.load(path, mmap_mode='r',allow_pickle=True)\n",
    "        data = np.float32(data)\n",
    "        # sampling 64 frames uniformly from the entire video\n",
    "        data = self.uniform_sampling(video=data, target_frames=64)\n",
    "        # whether to utilize the data augmentation\n",
    "        if  self.data_aug:\n",
    "            data[...,:3] = self.color_jitter(data[...,:3])\n",
    "            data = self.random_flip(data, prob=0.5)\n",
    "        # normalize rgb images and optical flows, respectively\n",
    "        data[...,:3] = self.normalize(data[...,:3])\n",
    "        data[...,3:] = self.normalize(data[...,3:])\n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b3c7bd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Video2Npy(file_path, resize=(224,224)):\n",
    "    \"\"\"Load video and tansfer it into .npy format\n",
    "    Args:\n",
    "        file_path: the path of video file\n",
    "        resize: the target resolution of output video\n",
    "    Returns:\n",
    "        frames: gray-scale video\n",
    "        flows: magnitude video of optical flows \n",
    "    \"\"\"\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    # Get number of frames\n",
    "    len_frames = int(cap.get(7))\n",
    "    # Extract frames from video\n",
    "    try:\n",
    "        frames = []\n",
    "        for i in range(len_frames-1):\n",
    "            _, frame = cap.read()\n",
    "            frame = cv2.resize(frame,resize, interpolation=cv2.INTER_AREA)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = np.reshape(frame, (224,224,3))\n",
    "            frames.append(frame)   \n",
    "    except:\n",
    "        print(\"Error: \", file_path, len_frames,i)\n",
    "    finally:\n",
    "        frames = np.array(frames)\n",
    "        cap.release()\n",
    "            \n",
    "    # Get the optical flow of video\n",
    "    flows = getOpticalFlow(frames)\n",
    "    \n",
    "    result = np.zeros((len(flows),224,224,5))\n",
    "    result[...,:3] = frames\n",
    "    result[...,3:] = flows\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dd6ee6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpticalFlow(video):\n",
    "    \"\"\"Calculate dense optical flow of input video\n",
    "    Args:\n",
    "        video: the input video with shape of [frames,height,width,channel]. dtype=np.array\n",
    "    Returns:\n",
    "        flows_x: the optical flow at x-axis, with the shape of [frames,height,width,channel]\n",
    "        flows_y: the optical flow at y-axis, with the shape of [frames,height,width,channel]\n",
    "    \"\"\"\n",
    "    # initialize the list of optical flows\n",
    "    gray_video = []\n",
    "    for i in range(len(video)):\n",
    "        img = cv2.cvtColor(video[i], cv2.COLOR_RGB2GRAY)\n",
    "        gray_video.append(np.reshape(img,(224,224,1)))\n",
    "\n",
    "    flows = []\n",
    "    for i in range(0,len(video)-1):\n",
    "        # calculate optical flow between each pair of frames\n",
    "        flow = cv2.calcOpticalFlowFarneback(gray_video[i], gray_video[i+1], None, 0.5, 3, 15, 3, 5, 1.2, cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "        # subtract the mean in order to eliminate the movement of camera\n",
    "        flow[..., 0] -= np.mean(flow[..., 0])\n",
    "        flow[..., 1] -= np.mean(flow[..., 1])\n",
    "        # normalize each component in optical flow\n",
    "        flow[..., 0] = cv2.normalize(flow[..., 0],None,0,255,cv2.NORM_MINMAX)\n",
    "        flow[..., 1] = cv2.normalize(flow[..., 1],None,0,255,cv2.NORM_MINMAX)\n",
    "        # Add into list \n",
    "        flows.append(flow)\n",
    "        \n",
    "    # Padding the last frame as empty array\n",
    "    flows.append(np.zeros((224,224,2)))\n",
    "      \n",
    "    return np.array(flows, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95d3b831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models  import Sequential, Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, Activation, LeakyReLU, Add, Multiply\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# from keras.layers.core import Lambda\n",
    "from tensorflow.keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "73164bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the rgb images \n",
    "def get_rgb(input_x):\n",
    "    rgb = input_x[...,:3]\n",
    "    return rgb\n",
    "\n",
    "# extract the optical flows\n",
    "def get_opt(input_x):\n",
    "    opt= input_x[...,3:5]\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8c3f1b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 64, 224, 224 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 64, 224, 224, 0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 64, 224, 224, 0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_66 (Conv3D)              (None, 64, 224, 224, 448         lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_74 (Conv3D)              (None, 64, 224, 224, 304         lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_67 (Conv3D)              (None, 64, 224, 224, 784         conv3d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_75 (Conv3D)              (None, 64, 224, 224, 784         conv3d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_36 (MaxPooling3D) (None, 64, 112, 112, 0           conv3d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_40 (MaxPooling3D) (None, 64, 112, 112, 0           conv3d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_68 (Conv3D)              (None, 64, 112, 112, 2320        max_pooling3d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_76 (Conv3D)              (None, 64, 112, 112, 2320        max_pooling3d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_69 (Conv3D)              (None, 64, 112, 112, 784         conv3d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_77 (Conv3D)              (None, 64, 112, 112, 784         conv3d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_37 (MaxPooling3D) (None, 64, 56, 56, 1 0           conv3d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_41 (MaxPooling3D) (None, 64, 56, 56, 1 0           conv3d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_70 (Conv3D)              (None, 64, 56, 56, 3 4640        max_pooling3d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_78 (Conv3D)              (None, 64, 56, 56, 3 4640        max_pooling3d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_71 (Conv3D)              (None, 64, 56, 56, 3 3104        conv3d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_79 (Conv3D)              (None, 64, 56, 56, 3 3104        conv3d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_38 (MaxPooling3D) (None, 64, 28, 28, 3 0           conv3d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_42 (MaxPooling3D) (None, 64, 28, 28, 3 0           conv3d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_72 (Conv3D)              (None, 64, 28, 28, 3 9248        max_pooling3d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_80 (Conv3D)              (None, 64, 28, 28, 3 9248        max_pooling3d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_73 (Conv3D)              (None, 64, 28, 28, 3 3104        conv3d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_81 (Conv3D)              (None, 64, 28, 28, 3 3104        conv3d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_39 (MaxPooling3D) (None, 64, 14, 14, 3 0           conv3d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_43 (MaxPooling3D) (None, 64, 14, 14, 3 0           conv3d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 64, 14, 14, 3 0           max_pooling3d_39[0][0]           \n",
      "                                                                 max_pooling3d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_44 (MaxPooling3D) (None, 8, 14, 14, 32 0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_82 (Conv3D)              (None, 8, 14, 14, 64 18496       max_pooling3d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_83 (Conv3D)              (None, 8, 14, 14, 64 12352       conv3d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_45 (MaxPooling3D) (None, 4, 7, 7, 64)  0           conv3d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_84 (Conv3D)              (None, 4, 7, 7, 64)  36928       max_pooling3d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_85 (Conv3D)              (None, 4, 7, 7, 64)  12352       conv3d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_46 (MaxPooling3D) (None, 2, 3, 3, 64)  0           conv3d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_86 (Conv3D)              (None, 2, 3, 3, 128) 73856       max_pooling3d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_87 (Conv3D)              (None, 2, 3, 3, 128) 49280       conv3d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_47 (MaxPooling3D) (None, 1, 1, 1, 128) 0           conv3d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 128)          0           max_pooling3d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          16512       flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           4128        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            66          dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 272,690\n",
      "Trainable params: 272,690\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(64,224,224,5))\n",
    "\n",
    "rgb = Lambda(get_rgb,output_shape=None)(inputs)\n",
    "opt = Lambda(get_opt,output_shape=None)(inputs)\n",
    "\n",
    "##################################################### RGB channel\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(rgb)\n",
    "rgb = MaxPooling3D(pool_size=(1,2,2))(rgb)\n",
    "##################################################### Optical Flow channel\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    16, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='sigmoid', padding='same')(opt)\n",
    "opt = Conv3D(\n",
    "    32, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='sigmoid', padding='same')(opt)\n",
    "opt = MaxPooling3D(pool_size=(1,2,2))(opt)\n",
    "##################################################### Fusion and Pooling\n",
    "x = Multiply()([rgb,opt])\n",
    "x = MaxPooling3D(pool_size=(8,1,1))(x)\n",
    "\n",
    "##################################################### Merging Block\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
    "\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = Conv3D(\n",
    "    64, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D(pool_size=(2,2,2))(x)\n",
    "\n",
    "x = Conv3D(\n",
    "    128, kernel_size=(1,3,3), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = Conv3D(\n",
    "    128, kernel_size=(3,1,1), strides=(1,1,1), kernel_initializer='he_normal', activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D(pool_size=(2,3,3))(x)\n",
    "\n",
    "##################################################### FC Layers\n",
    "X = Flatten()(x)\n",
    "x = Dense(128,activation='relu')(X)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Build the model\n",
    "pred = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "311981a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# # import kears\n",
    "# from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model \n",
    "# parallel_model = multi_gpu_model(model, gpus=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1e673c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2a42527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.7)\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "reduce_lr = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "975b740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "import tensorflow.keras\n",
    "\n",
    "class MyCbk(tensorflow.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, model):\n",
    "         self.model_to_save = model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model_to_save.save('Logs/model_at_epoch_%d.h5' % (epoch+1))\n",
    "\n",
    "check_point = MyCbk(model)\n",
    "\n",
    "\n",
    "filename = 'ours_log.csv'\n",
    "csv_logger = CSVLogger(filename, separator=',', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3ac82fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [check_point, csv_logger, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "246e3120",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs  = 30\n",
    "num_workers = 16\n",
    "batch_size  = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "501bb973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save2Npy(file_dir, save_dir):\n",
    "    \"\"\"Transfer all the videos and save them into specified directory\n",
    "    Args:\n",
    "        file_dir: source folder of target videos\n",
    "        save_dir: destination folder of output .npy files\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    # List the files\n",
    "    videos = os.listdir(file_dir)\n",
    "    for v in tqdm(videos):\n",
    "        # Split video name\n",
    "        video_name = v.split('.')[0]\n",
    "        # Get src \n",
    "        video_path = os.path.join(file_dir, v)\n",
    "        # Get dest \n",
    "        save_path = os.path.join(save_dir, video_name+'.npy') \n",
    "        # Load and preprocess video\n",
    "        data = Video2Npy(file_path=video_path, resize=(224,224))\n",
    "        data = np.uint8(data)\n",
    "        # Save as .npy file\n",
    "        np.save(save_path, data)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6c361d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\go_ai\\last-crime\\ourliv\\31-23_33-45 (1).mp4\n"
     ]
    }
   ],
   "source": [
    "dir = r\"E:\\go_ai\\last-crime\\ourliv\\31-23_33-45 (1).mp4\"\n",
    "print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4aa75da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:41<00:00, 41.52s/it]\n"
     ]
    }
   ],
   "source": [
    "source_path = r'E:\\go_ai\\last-crime\\video'\n",
    "target_path = r'E:\\go_ai\\last-crime\\data\\sam\\vi'\n",
    "# save_path = os.path.join(r\"E:\\go_ai\\last-crime\\data\\sam\\vi\", video_name+'.npy')\n",
    "# np.save(save_path, data)\n",
    "\n",
    "Save2Npy(source_path, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9e2e6c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-68d769f5cd5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnumber_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0monlyfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"upload\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0monlyfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'E:\\go_ai\\last-crime\\data\\our\\vid'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'E:\\go_ai\\last-crime\\data\\our\\vid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "s=\"yes\"\n",
    "if s==\"yes\":\n",
    "    onlyfiles = [f for f in listdir(r'E:\\go_ai\\last-crime\\data\\sam\\vi') if isfile(join(r'E:\\go_ai\\last-crime\\data\\sam\\vi', f))]\n",
    "    list = os.listdir(r'E:\\go_ai\\last-crime\\data\\sam\\vi') # dir is your directory path\n",
    "    number_files = len(list)\n",
    "    print(number_files)\n",
    "    print(onlyfiles[0])\n",
    "elif s==\"upload\":\n",
    "    onlyfiles = [f for f in listdir(r'E:\\go_ai\\last-crime\\data\\our\\vid') if isfile(join(r'E:\\go_ai\\last-crime\\data\\our\\vid', f))]\n",
    "    list = os.listdir(r'E:\\go_ai\\last-crime\\data\\our\\vid') # dir is your directory path\n",
    "    number_files = len(list)\n",
    "    print(number_files)\n",
    "#     print(onlyfiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "35d75ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import schedule\n",
    "# import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3c757583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 files belonging to 1 classes.\n",
      "        vi :  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator = DataGenerator(directory=r'E:\\go_ai\\last-crime\\data\\train', \n",
    "                                batch_size=batch_size, \n",
    "                                data_augmentation=True)\n",
    "\n",
    "val_generator = DataGenerator(directory=r'E:\\go_ai\\last-crime\\data\\sam',\n",
    "                              batch_size=batch_size, \n",
    "                              data_augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fd0b8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "hist = model.fit(train_generator, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=True, \n",
    "    epochs=num_epochs,\n",
    "    workers=num_workers ,\n",
    "    max_queue_size=4,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e5e51ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4064002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "from tensorflow.keras.models import load_model\n",
    "# hist = load_model('E:\\go ai\\last-crime\\model_at_epoch_1.h5')\n",
    "# model.load_weights('E:\\go_ai\\last-crime\\keras_model.h5')\n",
    "# filename = 'finalized_model.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))\n",
    "# model.save()\n",
    "hist = load_model('keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "18bea17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"crime_model.h5\")\n",
    "def addData(lat_lang,time):\n",
    "    ref = db.reference(\"/\")\n",
    "    res=ref.get(\"/\")\n",
    "    print(res[0])\n",
    "    res[0][lat_lang]=time\n",
    "    res=ref.set(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3b54287a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002B08CA17DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "pred = hist.predict(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "15edf8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[0.88542646 0.11457354]]\n"
     ]
    }
   ],
   "source": [
    "# e = datetime.datetime.now()\n",
    "# print(type(e))\n",
    "# date_time = e.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "# print(\"date and time:\", date_time)\n",
    "# a = e.toString()\n",
    "print(number_files)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4540f222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date and time: 06/12/2022, 08:45:24\n",
      "12-9259_ 77-6229.npy\n",
      "<class 'str'>\n",
      "12-9259_ 77-6229.npy  crime has been detected at  2022-06-12 08:45:24.205547\n"
     ]
    }
   ],
   "source": [
    "for i in range(number_files):\n",
    "    if pred[i][0] > pred[i][1]:\n",
    "        e = datetime.datetime.now()\n",
    "        date_time = e.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "        print(\"date and time:\", date_time)\n",
    "        print(onlyfiles[i])\n",
    "        name = onlyfiles[i].replace(\".npy\",\"\")\n",
    "        print(type(onlyfiles[i]))\n",
    "        print(onlyfiles[i],\" crime has been detected at \",e)\n",
    "#         addData(name,\"image\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e039327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f3f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
